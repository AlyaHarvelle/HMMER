{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "561d31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "from os import path\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from Bio.Blast import NCBIXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa0be3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get current working directory :  /Users/alina/Desktop/Internship-work/Internship\n"
     ]
    }
   ],
   "source": [
    "print('Get current working directory : ', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19f41db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/alina/Desktop/Internship-work/Internship/BLAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696d2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial function 'process_hsp_regions'\n",
    "\n",
    "def process_hsp_regions(hsp, doc_query, doc_subject, th_id=0.8, th_pos=0.9, th_len=10, th_gap=0.2):\n",
    "    \"\"\"\n",
    "    Assign an alignment for each set of region (different mobidb features, keys)\n",
    "    \"\"\"\n",
    "    valid_regions = []\n",
    "    for key in doc_query:\n",
    "        # Skip proteins already manually curated with this feature (key)\n",
    "        if key not in doc_subject:\n",
    "            for region in doc_query[key][\"regions\"]:\n",
    "\n",
    "                q_r_len = region[1] - region[0] + 1  # query region length without gaps\n",
    "\n",
    "                # Values relative to the alignment fragment that regards the query region\n",
    "                m = 0  # matches in the alignment\n",
    "                ident = 0  # identical in the alignment\n",
    "                g = 0  # gaps in the alignment\n",
    "\n",
    "                # Gaps till the end of the considered region. Usefult to map positions to the ungapped sequences\n",
    "                g_q = 0\n",
    "                g_s = 0\n",
    "\n",
    "                # The aligned fagments, including gaps (can start after the actual region start of the query sequence and finish before)\n",
    "                q_seq = []\n",
    "                s_seq = []\n",
    "\n",
    "                # The actual position of the aligned region in the subject ungapped sequence\n",
    "                s_start = None\n",
    "                s_end = None\n",
    "\n",
    "                for i, (l_q, l_s) in enumerate(zip(hsp.query, hsp.sbjct)):\n",
    "\n",
    "                    # Gaps\n",
    "                    if l_q == \"-\":\n",
    "                        g_q += 1\n",
    "                    if l_s == \"-\":\n",
    "                        g_s += 1\n",
    "\n",
    "                    if region[0] <= (i + hsp.query_start - g_q) <= region[1]:\n",
    "                        q_seq.append(l_q)\n",
    "                        s_seq.append(l_s)\n",
    "\n",
    "                        # Matches and identities\n",
    "                        if l_q != \"-\" and l_s != \"-\":\n",
    "                            m += 1\n",
    "                            if l_q == l_s:\n",
    "                                ident += 1\n",
    "                        else:\n",
    "                            g += 1\n",
    "\n",
    "                        # Start end positions\n",
    "                        if l_s != \"-\":\n",
    "                            s_end = i + hsp.sbjct_start - g_s\n",
    "                            if not s_start:\n",
    "                                s_start = s_end\n",
    "\n",
    "                if s_start and s_end:\n",
    "                    s_r_len = s_end - s_start + 1\n",
    "                    ident_perc = 2 * ident / (s_r_len + q_r_len)\n",
    "                    m_perc = 2 * m / (s_r_len + q_r_len)\n",
    "                    g_perc = 2 * g / (s_r_len + q_r_len)\n",
    "\n",
    "                    # TODO check gaps in the query\n",
    "                    if q_r_len >= th_len and s_r_len >= th_len and ident_perc >= th_id and m_perc >= th_pos and g_perc <= th_gap:\n",
    "                        n_key = \"homology-\" + \"-\".join(key.split(\"-\")[1:])\n",
    "                        valid_regions.append((key, n_key, q_r_len, s_r_len, s_start, s_end, m_perc, ident_perc, g_perc))\n",
    "\n",
    "    return valid_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e7bb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial function 'process_blast'\n",
    "\n",
    "def process_blast(curated_file, input_dir, out_file_regions, th_evalue=0.01):\n",
    "    curated = {}  # {uniprot_id: {key: {source_id: \"\", regions: [], content_fraction: 0, content_count: 0 }}}\n",
    "    with open(curated_file) as f:\n",
    "        for line in f:\n",
    "            doc = json.loads(line)\n",
    "            key = list(doc.keys())\n",
    "            key.remove(\"acc\")\n",
    "            key = key[0]\n",
    "            curated.setdefault(doc[\"acc\"], {})[key] = doc[key]\n",
    "    logging.info(\"Curated accessions {}\".format(len(curated)))\n",
    "\n",
    "    with open(out_file_regions, \"w\") as fout:\n",
    "        for file_name in os.listdir(input_dir):\n",
    "            logging.info(\"Processing {}\".format(file_name))\n",
    "            with open(\"{}/{}\".format(input_dir, file_name)) as f:\n",
    "\n",
    "                # Iterate queries\n",
    "                blast_records = NCBIXML.parse(f)\n",
    "                for blast_record in blast_records:\n",
    "\n",
    "                    # Iterate query alignments\n",
    "                    query_id = blast_record.query.split(\"|\")[1]\n",
    "                    if curated.get(query_id):\n",
    "                        for alignment in blast_record.alignments:\n",
    "                            subject_id = alignment.title.split(\"|\")[1]\n",
    "                            # print(query_id, subject_id, blast_record.query_length, alignment.length)\n",
    "                            # if query_id == \"P09651\" and subject_id == \"A0A3Q7R181\":\n",
    "                            for hsp in alignment.hsps:\n",
    "                                if hsp.expect < th_evalue:\n",
    "\n",
    "                                    # Calculate region overlap\n",
    "                                    for key, n_key, q_r_len, s_r_len, s_start, s_end, m_perc, ident_perc, g_perc in process_hsp_regions(hsp, curated[\n",
    "                                        query_id], curated.get(subject_id, {})):\n",
    "                                        fout.write(\"{} {} {} {} {} {} {} {} {:.3f} {:.3f} {:.3f}\\n\".format(subject_id,\n",
    "                                                                                                    query_id,\n",
    "                                                                                                    n_key,\n",
    "                                                                                                    curated[query_id][\n",
    "                                                                                                        key].get(\n",
    "                                                                                                        \"source_id\"),\n",
    "                                                                                                    alignment.length, # The subject length, full sequence\n",
    "                                                                                                    blast_record.query_length,\n",
    "                                                                                                    s_start,\n",
    "                                                                                                    s_end,\n",
    "                                                                                                    m_perc,\n",
    "                                                                                                    ident_perc,\n",
    "                                                                                                    g_perc))\n",
    "                    else:\n",
    "                        logging.warning(\"Missing query ID in the curated file {}\".format(query_id))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f9e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED process_blast\n",
    "# the key has been changed\n",
    "\n",
    "def process_blast(curated_file, input_dir, out_file_regions, th_evalue=0.01):\n",
    "    curated = {}\n",
    "    with open('homology.mjson') as f:\n",
    "        for line in f:\n",
    "            doc = json.loads(line)\n",
    "            key = list(doc.keys())\n",
    "            key.remove(\"acc\")\n",
    "            key = key[0]\n",
    "            source_id = doc[key]['regions_ids'][0].split('(')[0]\n",
    "            curated.setdefault(source_id, {doc['acc']: {'regions': doc[key]['regions'], \n",
    "                                            'content_fraction': doc[key]['content_fraction'], \n",
    "                                            'content_count': doc[key]['content_count']}})\n",
    "            logging.info(\"Curated accessions {}\".format(len(curated)))\n",
    "        logging.info(\"Finished processing file.\")\n",
    "\n",
    "        with open(out_file_regions, \"w\") as fout:\n",
    "            for file_name in os.listdir(input_dir):\n",
    "                logging.info(\"Processing {}\".format(file_name))\n",
    "                with open(\"{}/{}\".format(input_dir, file_name)) as f:\n",
    "\n",
    "                    # Iterate queries\n",
    "                    blast_records = NCBIXML.parse(f)\n",
    "                    for blast_record in blast_records:\n",
    "\n",
    "                        # Iterate query alignments\n",
    "                        query_id = blast_record.query.split(\"|\")[1]\n",
    "                        if curated.get(query_id):\n",
    "                            for alignment in blast_record.alignments:\n",
    "                                subject_id = alignment.title.split(\"|\")[1]\n",
    "                                for hsp in alignment.hsps:\n",
    "                                    if hsp.expect < th_evalue:\n",
    "\n",
    "                                        # Calculate region overlap\n",
    "                                        for key, n_key, q_r_len, s_r_len, s_start, s_end, m_perc, ident_perc, g_perc in process_hsp_regions(hsp, curated[\n",
    "                                            query_id], curated.get(subject_id, {})):\n",
    "                                            fout.write(\"{} {} {} {} {} {} {} {} {:.3f} {:.3f} {:.3f}\\n\".format(subject_id,\n",
    "                                                                                                        query_id,\n",
    "                                                                                                        n_key,\n",
    "                                                                                                        curated[query_id][\n",
    "                                                                                                            key].get(\n",
    "                                                                                                            \"source_id\"),\n",
    "                                                                                                        alignment.length, # The subject length, full sequence\n",
    "                                                                                                        blast_record.query_length,\n",
    "                                                                                                        s_start,\n",
    "                                                                                                        s_end,\n",
    "                                                                                                        m_perc,\n",
    "                                                                                                        ident_perc,\n",
    "                                                                                                        g_perc))\n",
    "                        else:\n",
    "                            logging.warning(\"Missing query ID in the curated file {}\".format(query_id))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c72e56fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'curated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcurated\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'curated' is not defined"
     ]
    }
   ],
   "source": [
    "curated # {uniprot_id: {key: {source_id: \"\", regions: [], \n",
    "        # content_fraction: 0, \n",
    "        # content_count: 0 }}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30544d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing query ID in the curated file Q8IWS0\n",
      "WARNING:root:Missing query ID in the curated file Q6F495\n",
      "WARNING:root:Missing query ID in the curated file Q92835\n",
      "WARNING:root:Missing query ID in the curated file Q86FP8\n",
      "WARNING:root:Missing query ID in the curated file Q9BZS1\n"
     ]
    }
   ],
   "source": [
    "process_blast('homology.mjson', directory, 'output.fasta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
